2026-01-20 11:21:49,012 - evalscope - INFO - Loading model openai-community/gpt2 ...
2026-01-20 11:21:51,716 - evalscope - INFO - Loading dataset from data/index_testset.jsonl
2026-01-20 11:21:52,199 - evalscope - INFO - Updating generation config ...
2026-01-20 11:21:52,849 - evalscope - INFO - Updating generation config ...
2026-01-20 11:21:53,373 - evalscope - INFO - Updating generation config ...
2026-01-20 11:21:53,982 - evalscope - INFO - Updating generation config ...
2026-01-20 11:21:53,997 - evalscope - INFO - Dump task config to outputs/20260120_000654/configs/task_config_0c21c7.yaml
2026-01-20 11:21:53,999 - evalscope - INFO - {
    "model": "openai-community/gpt2",
    "model_id": "gpt2",
    "model_args": {
        "revision": "master",
        "precision": "torch.float16"
    },
    "model_task": "text_generation",
    "template_type": null,
    "chat_template": null,
    "datasets": [
        "data_collection"
    ],
    "dataset_args": {
        "data_collection": {
            "shuffle": true
        }
    },
    "dataset_dir": "/Users/xuhu.6736/.cache/modelscope/hub/datasets",
    "dataset_hub": "modelscope",
    "generation_config": {
        "temperature": 0.0
    },
    "eval_type": "checkpoint",
    "eval_backend": "Native",
    "eval_config": null,
    "stage": "all",
    "limit": null,
    "eval_batch_size": 5,
    "mem_cache": false,
    "use_cache": "outputs/20260120_000654",
    "work_dir": "outputs/20260120_000654",
    "outputs": null,
    "ignore_errors": false,
    "debug": false,
    "dry_run": false,
    "seed": 42,
    "api_url": null,
    "api_key": "EMPTY",
    "timeout": null,
    "stream": false,
    "judge_strategy": "auto",
    "judge_worker_num": 1,
    "judge_model_args": {},
    "analysis_report": false
}
2026-01-20 11:21:54,001 - evalscope - INFO - Reuse from outputs/20260120_000654/predictions/gpt2/index_testset.jsonl. Loaded 6 samples, remain 4 samples.
2026-01-20 11:22:53,490 - evalscope - INFO - Args: Task config is provided with TaskConfig type.
2026-01-20 11:22:53,493 - evalscope - INFO - Set resume from outputs/20260119_232050
2026-01-20 11:22:53,494 - evalscope - INFO - Loading model openai-community/gpt2 ...
2026-01-20 11:22:55,592 - evalscope - INFO - Loading dataset from data/index_testset.jsonl
2026-01-20 11:22:56,198 - evalscope - INFO - Updating generation config ...
2026-01-20 11:22:56,705 - evalscope - INFO - Updating generation config ...
2026-01-20 11:22:57,225 - evalscope - INFO - Updating generation config ...
2026-01-20 11:22:57,845 - evalscope - INFO - Updating generation config ...
2026-01-20 11:22:57,871 - evalscope - INFO - Dump task config to outputs/20260119_232050/configs/task_config_2df7bf.yaml
2026-01-20 11:22:57,873 - evalscope - INFO - {
    "model": "openai-community/gpt2",
    "model_id": "gpt2",
    "model_args": {
        "revision": "master",
        "precision": "torch.float16"
    },
    "model_task": "text_generation",
    "template_type": null,
    "chat_template": null,
    "datasets": [
        "data_collection"
    ],
    "dataset_args": {
        "data_collection": {
            "shuffle": true
        }
    },
    "dataset_dir": "/Users/xuhu.6736/.cache/modelscope/hub/datasets",
    "dataset_hub": "modelscope",
    "generation_config": {
        "temperature": 0.0
    },
    "eval_type": "checkpoint",
    "eval_backend": "Native",
    "eval_config": null,
    "stage": "all",
    "limit": null,
    "eval_batch_size": 5,
    "mem_cache": false,
    "use_cache": "outputs/20260119_232050",
    "work_dir": "outputs/20260119_232050",
    "outputs": null,
    "ignore_errors": false,
    "debug": false,
    "dry_run": false,
    "seed": 42,
    "api_url": null,
    "api_key": "EMPTY",
    "timeout": null,
    "stream": false,
    "judge_strategy": "auto",
    "judge_worker_num": 1,
    "judge_model_args": {},
    "analysis_report": false
}
2026-01-20 11:22:57,877 - evalscope - INFO - Reuse from outputs/20260119_232050/predictions/gpt2/index_testset.jsonl. Loaded 25 samples, remain 0 samples.
2026-01-20 11:22:57,878 - evalscope - INFO - use_cache=outputs/20260119_232050, reloading the review file: outputs/20260119_232050/reviews/gpt2
2026-01-20 11:22:58,133 - evalscope - INFO - subset_level Report:
+-----------+-----------------+--------------+---------------+---------------+-------+
| task_type |     metric      | dataset_name |  subset_name  | average_score | count |
+-----------+-----------------+--------------+---------------+---------------+-------+
|           | AverageAccuracy |    ceval     |     logic     |      0.0      |   4   |
|           | AverageAccuracy |    gsm8k     |     main      |      0.0      |   2   |
|           | AverageAccuracy |     arc      | ARC-Challenge |      0.0      |   1   |
|           | AverageAccuracy |     arc      |   ARC-Easy    |      0.0      |   1   |
|           |  AveragePass@1  |    aime25    |  AIME2025-I   |      0.0      |   1   |
|           |  AveragePass@1  |    aime25    |  AIME2025-II  |      0.0      |   1   |
+-----------+-----------------+--------------+---------------+---------------+-------+
2026-01-20 11:22:58,134 - evalscope - INFO - dataset_level Report:
+-----------+-----------------+--------------+---------------+-------+
| task_type |     metric      | dataset_name | average_score | count |
+-----------+-----------------+--------------+---------------+-------+
|           | AverageAccuracy |    ceval     |      0.0      |   4   |
|           | AverageAccuracy |     arc      |      0.0      |   2   |
|           | AverageAccuracy |    gsm8k     |      0.0      |   2   |
|           |  AveragePass@1  |    aime25    |      0.0      |   2   |
+-----------+-----------------+--------------+---------------+-------+
2026-01-20 11:22:58,134 - evalscope - INFO - task_level Report:
+-----------+-----------------+---------------+-------+
| task_type |     metric      | average_score | count |
+-----------+-----------------+---------------+-------+
|           | AverageAccuracy |      0.0      |   8   |
|           |  AveragePass@1  |      0.0      |   2   |
+-----------+-----------------+---------------+-------+
2026-01-20 11:22:58,135 - evalscope - INFO - tag_level Report:
+------+-----------------+---------------+-------+
| tags |     metric      | average_score | count |
+------+-----------------+---------------+-------+
|  en  | AverageAccuracy |      0.0      |   4   |
|  zh  | AverageAccuracy |      0.0      |   4   |
|  en  |  AveragePass@1  |      0.0      |   2   |
+------+-----------------+---------------+-------+
2026-01-20 11:22:58,135 - evalscope - INFO - category_level Report:
+-----------------+-----------+-----------------+---------------+-------+
|    category0    | category1 |     metric      | average_score | count |
+-----------------+-----------+-----------------+---------------+-------+
| reasoning_index |   logic   | AverageAccuracy |      0.0      |   6   |
| reasoning_index |   math    | AverageAccuracy |      0.0      |   2   |
| reasoning_index |   math    |  AveragePass@1  |      0.0      |   2   |
+-----------------+-----------+-----------------+---------------+-------+
2026-01-20 11:22:58,137 - evalscope - INFO - Skipping report analysis (`analysis_report=False`).
2026-01-20 11:22:58,138 - evalscope - INFO - Report saved to outputs/20260119_232050/reports/gpt2/index_testset.json
2026-01-20 11:22:58,140 - evalscope - INFO - Overall report table: 
+---------+---------------+----------+--------------------+-------+---------+-----------------+---------+
| Model   | Dataset       | Metric   | Subset             |   Num |   Score | Cat.0           | Cat.1   |
+=========+===============+==========+====================+=======+=========+=================+=========+
| gpt2    | index_testset | Average  | arc/ARC-Challenge  |     1 |       0 | reasoning_index | logic   |
+---------+---------------+----------+--------------------+-------+---------+-----------------+---------+
| gpt2    | index_testset | Average  | arc/ARC-Easy       |     1 |       0 | reasoning_index | logic   |
+---------+---------------+----------+--------------------+-------+---------+-----------------+---------+
| gpt2    | index_testset | Average  | ceval/logic        |     4 |       0 | reasoning_index | logic   |
+---------+---------------+----------+--------------------+-------+---------+-----------------+---------+
| gpt2    | index_testset | Average  | aime25/AIME2025-I  |     1 |       0 | reasoning_index | math    |
+---------+---------------+----------+--------------------+-------+---------+-----------------+---------+
| gpt2    | index_testset | Average  | aime25/AIME2025-II |     1 |       0 | reasoning_index | math    |
+---------+---------------+----------+--------------------+-------+---------+-----------------+---------+
| gpt2    | index_testset | Average  | gsm8k/main         |     2 |       0 | reasoning_index | math    |
+---------+---------------+----------+--------------------+-------+---------+-----------------+---------+
| gpt2    | index_testset | Average  | OVERALL            |    10 |       0 | -               |         |
+---------+---------------+----------+--------------------+-------+---------+-----------------+---------+ 

2026-01-20 11:22:58,245 - evalscope - INFO - Finished evaluation for gpt2 on ['data_collection']
2026-01-20 11:22:58,246 - evalscope - INFO - Output directory: outputs/20260119_232050

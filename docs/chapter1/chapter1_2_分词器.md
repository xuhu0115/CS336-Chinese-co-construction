# 分词器
分词器是连接人类自然语言与机器计算的“关键桥梁”，负责将非结构化的文本高效地编码为模型可理解的数字序列（Tokens）。其地位至关重要，它决定了模型的输入形式。我们可以将大语言模型（LLM）视为一位阅读者，分词器则执行了文本的“认知拆解”即将连续的文本流切分为具备最小语义或功能意义的基本单元，类似于人类阅读时对词汇或音节的本能识别。本章节将剖析分词器实现文本“数字化”的核心原理，并探讨BPE等主流分词算法的实际应用。

<p align="center">
<img width="500" height="300" alt="0e717e4cf0df64875a271123bf962631" src="https://github.com/user-attachments/assets/a53dd727-8682-4314-92dc-3b3e18dfaf58" />
</p>

### 1分词器原理
在我们把海量数据喂给大模型之前，必须先经过一道关键工序——分词。分词器常被视为LLM的一部分，但它其实拥有独立的训练生命周期。我们需要利用正则表达式对原始文本进行预处理，并统计构建出一套高效的*词元——数字*映射表。这个映射过程决定了模型眼中的世界是由字、词还是更碎的片段组成的，直接影响后续模型对语义的理解效率。也正因如此，[分词器](https://tiktokenizer.vercel.app/?model=deepseek-ai%2FDeepSeek-R1)虽独立训练却与LLM保持着“强耦合”的关系。

### 2常用的分词器

#### 2.1 字符分词器

#### 2.2 字节分词器

#### 2.3 词级分词器

#### 2.4 BPE分词器


# 数据

在前面的课程中，讨论的是在训练数据已经给定的前提下，如何通过架构设计、优化方法、分词技术和规模扩展来训练更强的模型；而从这一讲开始，我们将转向一个更根本的问题：语言模型究竟应该用什么数据来训练。现实中的大模型研发表明，数据往往比模型结构本身更关键——主流基础模型几乎都会公开完整的架构与训练流程，却对训练数据的具体构成保持高度概括，这恰恰说明数据是最难复制、也最具竞争价值的部分。即便在自监督学习成为主流之后，数据工程依然贯穿整个训练过程，数据的收集、清洗、过滤与组合方式直接决定了模型能学到什么、学不到什么；而由于数据具有明显的长尾特性，模型在真实世界中的能力边界，最终由训练数据的覆盖范围所定义。

>数据的长尾特性是常见样本在训练数据中出现得非常频繁，而专业领域或罕见场景的数据在单一类别中出现次数很少，但由于这类少见样本的类型数量极多，它们共同决定了大语言模型能力的覆盖范围和泛化边界。

## 11.1 数据获取


<div align="center">
  


   <p>图11.1 数据来源</p>
 </div>


数据对于大语言模型（LLM）的训练至关重要，其过程通常分为三个阶段：
- **预训练阶段** 使用海量原始网络数据，使模型掌握基础语言知识和广泛语义。
- **中期训练阶段** 采用精选的高质量文档，重点提升数学、代码、长文本理解等特定能力。
- **后期训练阶段** 通过指令微调、对话数据或强化学习，使模型具备交互能力，并在此阶段完成安全对齐，确保模型输出符合预期行为和价值规范。


### 11.1.1 预训练数据

预训练阶段的数据来源非常广泛，其核心目标是捕捉人类语言的规律、常识知识以及文本间的关系，并通过在海量数据上训练模型，使大语言模型（LLM）获得对文本语义、语言结构和上下文理解的初步能力。为了系统性地组织，预训练数据通常可分为以下几大类，每类数据在模型能力形成中发挥不同作用：

1. **网络抓取数据**是预训练数据中**规模最大、覆盖最广的来源**，可被视为“互联网的学术近似集”。它为模型提供丰富、多样化的文本，但原始数据往往伴随大量噪声，如垃圾信息、重复内容和非自然语言文本等，因此必须经过严格的清洗和过滤，典型数据集包括：

    - **Common Crawl（通用爬虫数据）**：自2007年以来每月抓取互联网快照，包含数万亿`token`，但是原始内容噪声大，需要复杂的数据清洗管线，包括去重、去垃圾文本、非自然语言过滤等。
    - **C4**：Google基于Common Crawl构建的清洗数据集，通过大规模启发式过滤去除短句、冒犯性语言和非自然文本，获得更干净、可直接用于训练的语料。
    - **WebText**：GPT-2和GPT-3的训练来源，其核心思路是**利用人类偏好进行筛选**仅抓取在Reddit上获得3个以上点赞的网页链接，以快速获取高质量、多样化的网络文本。
    - **RefinedWeb**：在严格过滤和去重的基础上，仅依靠高质量网络文本就能训练出强大的模型，进一步提升预训练数据的有效性和质量。

2. **高质量的百科与书籍**提供逻辑严密、长程关联性强的文本，对于模型理解复杂上下文、提升知识完整性和语言组织能力至关重要。
  
    - **Wikipedia（维基百科）**：几乎所有主流模型的标配，内容中立、有据可查、无原创观点，常被视为衡量其他数据质量的“金标准”。
    - **书籍库**：
    
      - **Project Gutenberg**：收录约7.5万本已过版权保护期的公版书籍，合法且易于获取。
      - **Libraries**：包含数百万本受版权保护书籍（如畅销小说等），但由于版权争议，部分数据集已被移除。

3. **专业领域的代码与学术资源**对于模型在推理、数学和编程能力上的提升至关重要。

    - **代码数据**：主要来源于 GitHub 的公共仓库，训练模型理解编程语法、逻辑结构和调试思路，从而提升逻辑推理和解决问题能力。
    - **学术论文**：包括arXiv物理、数学、计算机科学等、PubMed Central生物医学文献、Semantic Scholar等，高质量学术语料有助于模型在科研和专业领域的语言理解能力。

4. **社交媒体与问答平台**可以帮助模型学习人类对话模式、问答逻辑和知识表达风格，尤其适合对话生成与交互场景。

    - **Stack Exchange**：包括Stack Overflow等问答网站，利用点赞和排序机制筛选高质量问答对。
    - **Reddit**：提供多样化的讨论文本，覆盖大量口语化表达和多元话题。
    - **Enron Emails**：少数公开的大规模真实邮件数据集，用于学习商务邮件写作风格与正式交流语言。

5. **合成数据与模型引导数据**，随着高质量自然语言数据的稀缺，开发者开始使用模型生成的**合成数据**来补充训练语料。

    - **模型过滤**：利用大模型如GPT-4评估网页内容的“教育价值”，仅保留高分文本如Phi-1 或Nemotron-CC的做法。
    - **合成任务**：让语言模型将低质量网页改写为高质量教学材料，或者根据百科、文档生成摘要、问答对等，进一步提升模型在特定任务上的表现。



## 11.2 数据处理

